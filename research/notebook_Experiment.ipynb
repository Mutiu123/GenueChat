{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import gradio as gr\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for conversation and document-based prompts\n",
    "template = \"\"\"You are a helpful assistant.\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistant:\"\"\"\n",
    "\n",
    "document_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a prompt template using PromptTemplate, which takes history and input as variables \n",
    "# and formats them according to the template string.\n",
    "PROMPT = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "# Create a prompt template for conversation\n",
    "llm = ChatGroq(\n",
    "    temperature=0, # Set the randomness of the model's responses\n",
    "    groq_api_key='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', # Get the API key from environment variables\n",
    "    model_name=\"llama-3.1-8b-instant\" # Specify the model name\n",
    ")\n",
    "memory = ConversationBufferMemory()   # Initialize memory to store conversation history\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=True, prompt=PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversation chain with LLM, memory, and prompt\n",
    "# Function to load and retrieve documents\n",
    "def load_and_retrieve(file):\n",
    "    file = PyPDFLoader(file).load() # Load the PDF file\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) # Split the document into chunks\n",
    "    chunks = splitter.split_documents(file)  # Split the loaded document into chunks\n",
    "    embeddings = HuggingFaceEmbeddings() # Generate embeddings for the document chunks\n",
    "    vectorstore = FAISS.from_documents(documents=chunks, embedding=embeddings) # Store the embeddings in a FAISS vector database\n",
    "    return vectorstore.as_retriever()  # Return a retriever for querying the vector database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a RAG (Retrieval-Augmented Generation) chain\n",
    "def rag_chain(file, question):\n",
    "    retriever = load_and_retrieve(file) # Load and retrieve document chunks\n",
    "    prompt = ChatPromptTemplate.from_template(document_template)  # Create a chat prompt template from the document template\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()} # Pass the context and question through the chain\n",
    "        | prompt  # Apply the prompt template\n",
    "        | llm  # Use the language model to generate a response\n",
    "        | StrOutputParser()  # Parse the output as a string\n",
    "    )\n",
    "    response = chain.invoke(question) # Invoke the chain with the question\n",
    "    return response  # Return the generated response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle chat interactions\n",
    "def handle_chat(file, question):  \n",
    "    if file:\n",
    "        response = rag_chain(file, question)   # Use the RAG chain if a file is provided\n",
    "    else:\n",
    "        response = conversation.predict(input=question)  # Use the conversation chain if no file is provided\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question\n",
    "question = \"What is good in being a programmer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant.\n",
      "Current conversation:\n",
      "\n",
      "Human: What is good in being a programmer\n",
      "AI Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: Being a programmer can be incredibly rewarding and offers many benefits. Here are some of the advantages of being a programmer:\n",
      "\n",
      "1. **Creative Freedom**: As a programmer, you have the ability to create something from scratch, bringing your ideas to life. You can design, develop, and implement solutions to real-world problems, which can be very fulfilling.\n",
      "\n",
      "2. **Constant Learning**: The field of programming is constantly evolving, with new technologies, frameworks, and languages emerging all the time. This means that programmers must stay up-to-date with the latest developments, which can be a fun and challenging experience.\n",
      "\n",
      "3. **Good Compensation**: Programmers are generally well-compensated, with median salaries ranging from $60,000 to over $100,000 depending on the location, experience, and industry.\n",
      "\n",
      "4. **Job Security**: The demand for skilled programmers is high, and the job market is expected to continue growing in the coming years. This means that programmers can enjoy a high level of job security.\n",
      "\n",
      "5. **Flexibility**: With the rise of remote work, programmers can often work from anywhere, at any time, as long as they have a reliable internet connection. This flexibility can be a major advantage for those who value work-life balance.\n",
      "\n",
      "6. **Opportunities for Advancement**: Experienced programmers can move into leadership roles, such as team lead or technical architect, or start their own companies. They can also specialize in a particular area, such as artificial intelligence or cybersecurity.\n",
      "\n",
      "7. **Sense of Accomplishment**: When a programmer completes a project, they can feel a sense of pride and accomplishment, knowing that they have created something that can make a real difference in people's lives.\n",
      "\n",
      "8. **Community**: The programming community is vast and active, with many online forums, meetups, and conferences where programmers can connect with others who share their interests.\n",
      "\n",
      "9. **Variety**: Programming involves working on a wide range of projects, from mobile apps to web applications to operating systems. This variety can keep the work interesting and prevent boredom.\n",
      "\n",
      "10. **Personal Growth**: Programming requires problem-solving, critical thinking, and analytical skills, which can help programmers develop their cognitive abilities and become more well-rounded individuals.\n",
      "\n",
      "Overall, being a programmer can be a highly rewarding and challenging career that offers many benefits and opportunities for growth and development.\n"
     ]
    }
   ],
   "source": [
    "# Print response\n",
    "file = None  # Replace with your file path if needed\n",
    "response = handle_chat(file, question)\n",
    "print(\"Response:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
